{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: N1 Analytics hash utility\n",
    "\n",
    "## First data provider (Alice)\n",
    "\n",
    "This notebook demonstrates local hashing of personally identifiable information (PII), upload to the entity service, and retrieval of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clkutil, version 0.4.5\r\n"
     ]
    }
   ],
   "source": [
    "!clkutil --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alice-credentials.txt  alice-hashed.json  alice.txt\r\n"
     ]
    }
   ],
   "source": [
    "# Our data is already in our local directory...\n",
    "!ls alice*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INDEX,NAME freetext,DOB YYYY/MM/DD,GENDER M or F\r\n",
      "500,Loran Urik,1949/09/03,M\r",
      "\r\n",
      "501,Arch Kaanana,1919/07/09,M\r",
      "\r\n",
      "502,Ewald Ronda,1972/02/12,M\r",
      "\r\n",
      "503,Tavian George,1958/04/25,M\r",
      "\r\n",
      "504,Elliott Palmieri,1958/06/05,M\r",
      "\r\n",
      "505,Lyda Chesson,1979/03/12,F\r",
      "\r\n",
      "506,King Saran,1990/08/21,M\r",
      "\r\n",
      "507,Lacy Motz,1985/11/06,F\r",
      "\r\n",
      "508,Syreeta Mieszala,2012/10/05,F\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head alice.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Locally hash PII data\n",
    "\n",
    "First we need to hash the PII file. To do that, the two data providers need to come up with a secret. The data linkage authority is not allowed to know this secret. Two words will do; here I'll use the name of a fish, `\"Smooth Oreo\"`.\n",
    "\n",
    "<img src=\"http://www.foxtrade.lv/assets/Uploads/_resampled/SetRatioSize350350-zeus-faber-sw.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: clkutil hash [OPTIONS] INPUT KEYS... OUTPUT\r\n",
      "\r\n",
      "  Process data to create CLKs\r\n",
      "\r\n",
      "  Given a file containing csv data as INPUT, and optionally a json document\r\n",
      "  defining the expected schema, verify the schema, then hash the data to\r\n",
      "  create CLKs writing to OUTPUT. Note the CSV file should contain a header\r\n",
      "  row - however this row is not used by this tool.\r\n",
      "\r\n",
      "  It is important that the keys are only known by the two data providers.\r\n",
      "  Two words should be provided. For example:\r\n",
      "\r\n",
      "  $clkutil hash input.txt horse staple output.txt\r\n",
      "\r\n",
      "  Use \"-\" to output to stdout.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -s, --schema FILENAME\r\n",
      "  --help                 Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!clkutil hash --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mAssuming default schema\u001b[0m\n",
      "\u001b[31mHashing data\u001b[0m\n",
      "\u001b[31mHeader Row: INDEX,NAME freetext,DOB YYYY/MM/DD,GENDER M or F\n",
      "\u001b[0m\n",
      "\u001b[31mCLK data written to alice-hashed.json\u001b[0m\n",
      "CPU times: user 32 ms, sys: 4 ms, total: 36 ms\n",
      "Wall time: 1.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hash the data using the secret keys, which the linkage authority doesn't know\n",
    "!clkutil hash alice.txt smooth oreo alice-hashed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take a sneak peek at the hashed data to convince ourselves that the created file isn't obviously full of PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"clks\": [\"9yBXbGFLdoFeMMMjexDiucYPZpngbHAV4QVMvgXSbxsn4NVjPNJPrCEk8YCFMfQKZsleJJcg8RTQ\\\\nfdFRdFBxYVFzxEnpREpGlKtkUBJpQqSh5ks3YynDGCg3WJYLVnNGI5RlZxBE8YetCnoqSRR0KBQ7\\\\nTwY0AUCuXJhk7FKkyCA=\", \"zytfDFAjU'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('alice-hashed.json').read(200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These \"clks\" are the *cryptographic long term keys*, sometimes refered to as Bloom filter hashes.\n",
    "\n",
    "\n",
    "## Step 2 - Upload\n",
    "Next we can upload this hashed data to the entity linkage service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: clkutil upload [OPTIONS] INPUT\r\n",
      "\r\n",
      "  Upload CLK data to entity matching server.\r\n",
      "\r\n",
      "  Given a json file containing hashed clk data as INPUT, upload to the\r\n",
      "  entity resolution service.\r\n",
      "\r\n",
      "  Use \"-\" to read from stdin.\r\n",
      "\r\n",
      "Options:\r\n",
      "  --mapping TEXT  Server identifier of the mapping\r\n",
      "  --apikey TEXT   Authentication API key for the server.\r\n",
      "  --server TEXT   Server address including protocol\r\n",
      "  --help          Show this message and exit.\r\n"
     ]
    }
   ],
   "source": [
    "!clkutil upload --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we need some authentication information from the linkage authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('9f942ffdf20a999bf7255a2111095c0d5aabe6a34d0a11e8',\n",
       " '92df0b3a4799c1bd4b17e77975ddcd140e9de3004ae12061')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Securely provided by the data linkage authority:\n",
    "with open('alice-credentials.txt','r') as f:\n",
    "    linkage_id, provider_token = f.read().split()\n",
    "\n",
    "linkage_id, provider_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data\n",
    "out = !clkutil upload \\\n",
    "    --mapping=\"$linkage_id\" \\\n",
    "    --apikey=\"$provider_token\" \\\n",
    "    alice-hashed.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every upload gets a receipt token. In some operating modes this receipt is required to access the results. For ease of use let's save this so we can use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out the receipt token\n",
    "receipt_token = out.grep(\"receipt-token\")[0].strip().split('\"receipt-token\": ')[1].strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ce81211a0706f23628c0470a466ac38ef3698123962bf713'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receipt_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check to see if the results are ready (which they won't be...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mChecking server status\u001b[0m\n",
      "\u001b[31mStatus: ok\u001b[0m\n",
      "\u001b[31mResponse code: 503\u001b[0m\n",
      "\u001b[31mNo result yet\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"current\": \"0\",\n",
      "    \"elapsed\": 0.0,\n",
      "    \"message\": \"Mapping isn't ready.\",\n",
      "    \"progress\": 0.0,\n",
      "    \"total\": \"NA\"\n",
      "}\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!clkutil results \\\n",
    "    --mapping=\"$linkage_id\" \\\n",
    "    --apikey=\"$receipt_token\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Bob has to do his part too! Afterwards we can come back to look at the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mChecking server status\u001b[0m\n",
      "\u001b[31mStatus: ok\u001b[0m\n",
      "\u001b[31mResponse code: 200\u001b[0m\n",
      "\u001b[31mReceived result\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!clkutil results \\\n",
    "    --mapping=\"$linkage_id\" \\\n",
    "    --apikey=\"$receipt_token\" --output=\"alice-results.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('alice-results.txt','r') as f:\n",
    "    alice_res = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this result is a new permutation - a new ordering for our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[625, 698, 390, 743, 671, 385, 288, 525, 579, 379]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_permutation = alice_res['permutation']\n",
    "alice_permutation[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reorder our local data with this new permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reorder(items, order):\n",
    "    neworder = items.copy()\n",
    "    for item, newpos in zip(items, order):\n",
    "        neworder[newpos] = item\n",
    "    \n",
    "    return neworder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('alice.txt', 'r') as f:\n",
    "    alice_raw = f.readlines()\n",
    "\n",
    "alice_reordered = reorder(alice_raw, alice_permutation)\n",
    "\n",
    "with open('alice-reordered.txt', 'wt') as f:\n",
    "    f.writelines(alice_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1865,Durward Iverslie,2007/01/15,M\\n',\n",
       " '1985,Mark Bedson,1966/03/10,F\\n',\n",
       " '1886,Brantlee Gislason,1995/08/29,M\\n',\n",
       " '867,Braulio Peinado,1950/06/12,M\\n',\n",
       " '767,Bernice Cabellero,1930/06/30,F\\n',\n",
       " '806,Milo Durling,1920/07/11,M\\n',\n",
       " '1649,Kya Candill,1960/05/27,F\\n',\n",
       " '1822,Mardell Becknell,1918/03/27,F\\n',\n",
       " '572,Blair Roewe,1969/03/29,F\\n',\n",
       " '979,Todd Torian,1917/01/14,M\\n']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_reordered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that Bob doesn't actually know which of these people line up with Alice's entities, because the mask is held by the linkage authority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
