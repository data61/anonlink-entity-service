{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Service Permutation Output\n",
    "\n",
    "This notebook demonstrates generating CLKs from PII, creating a new mapping on the entity service, and how to retrieve the results. The output type is permutation and unencrypted mask.\n",
    "\n",
    "The sections are usually run on different companies - but for illustration all is carried out in this one file. The participants providing data are *Alice* and *Bob*, and the analyst acting the integration authority.\n",
    "\n",
    "### Who learns what?\n",
    "\n",
    "Alice and Bob will both generate and upload their CLKs. After the linkage has been carried out they will be able to retrieve a `permutation` - a reordering of their respective data sets such that shared entities line up.\n",
    "\n",
    "The analyst - who creates the linkage project - learns the `mask`. The mask is a binary vector that indicates which rows in the permuted data sets are aligned. Note this reveals how many entities are shared. \n",
    "\n",
    "### Steps\n",
    "\n",
    "* Check connection to Entity Service\n",
    "* Data preparation\n",
    "  * Write CSV files with PII\n",
    "  * Create a Linkage Schema\n",
    "  \n",
    "* Create Linkage Project\n",
    "* Generate CLKs from PII\n",
    "* Upload the PII\n",
    "* Retrieve and analyse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Connection\n",
    "\n",
    "If you are connecting to a custom entity service, change the address here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://es.data61.xyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mConnecting to Entity Matching Server: https://es.data61.xyz\u001b[0m\n",
      "\u001b[31mResponse: 200\u001b[0m\n",
      "\u001b[31mStatus: ok\u001b[0m\n",
      "{\"number_mappings\": 3434, \"rate\": 3347647, \"status\": \"ok\"}\n"
     ]
    }
   ],
   "source": [
    "!clkutil status --server \"{url}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Following the clkhash tutorial we will use a dataset from the `recordlinkage` library. We will just write both datasets out to temporary CSV files.\n",
    "\n",
    "If you are following along yourself you may have to adjust the file names in all the `!clkutil` commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "from recordlinkage.datasets import load_febrl4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets written to /tmp/tmpc57_lneo and /tmp/tmpv20xs4ku\n"
     ]
    }
   ],
   "source": [
    "dfA, dfB = load_febrl4()\n",
    "\n",
    "a_csv = NamedTemporaryFile('w')\n",
    "a_clks = NamedTemporaryFile('w', suffix='.json')\n",
    "dfA.to_csv(a_csv)\n",
    "a_csv.seek(0)\n",
    "\n",
    "b_csv = NamedTemporaryFile('w')\n",
    "b_clks = NamedTemporaryFile('w', suffix='.json')\n",
    "dfB.to_csv(b_csv)\n",
    "b_csv.seek(0)\n",
    "\n",
    "dfA.head()\n",
    "print(\"Datasets written to {} and {}\".format(a_csv.name, b_csv.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1070-org</th>\n",
       "      <td>michaela</td>\n",
       "      <td>neumann</td>\n",
       "      <td>8</td>\n",
       "      <td>stanley street</td>\n",
       "      <td>miami</td>\n",
       "      <td>winston hills</td>\n",
       "      <td>4223</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19151111</td>\n",
       "      <td>5304218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <td>courtney</td>\n",
       "      <td>painter</td>\n",
       "      <td>12</td>\n",
       "      <td>pinkerton circuit</td>\n",
       "      <td>bega flats</td>\n",
       "      <td>richlands</td>\n",
       "      <td>4560</td>\n",
       "      <td>vic</td>\n",
       "      <td>19161214</td>\n",
       "      <td>4066625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4405-org</th>\n",
       "      <td>charles</td>\n",
       "      <td>green</td>\n",
       "      <td>38</td>\n",
       "      <td>salkauskas crescent</td>\n",
       "      <td>kela</td>\n",
       "      <td>dapto</td>\n",
       "      <td>4566</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19480930</td>\n",
       "      <td>4365168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1288-org</th>\n",
       "      <td>vanessa</td>\n",
       "      <td>parr</td>\n",
       "      <td>905</td>\n",
       "      <td>macquoid place</td>\n",
       "      <td>broadbridge manor</td>\n",
       "      <td>south grafton</td>\n",
       "      <td>2135</td>\n",
       "      <td>sa</td>\n",
       "      <td>19951119</td>\n",
       "      <td>9239102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3585-org</th>\n",
       "      <td>mikayla</td>\n",
       "      <td>malloney</td>\n",
       "      <td>37</td>\n",
       "      <td>randwick road</td>\n",
       "      <td>avalind</td>\n",
       "      <td>hoppers crossing</td>\n",
       "      <td>4552</td>\n",
       "      <td>vic</td>\n",
       "      <td>19860208</td>\n",
       "      <td>7207688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             given_name   surname street_number            address_1  \\\n",
       "rec_id                                                                 \n",
       "rec-1070-org   michaela   neumann             8       stanley street   \n",
       "rec-1016-org   courtney   painter            12    pinkerton circuit   \n",
       "rec-4405-org    charles     green            38  salkauskas crescent   \n",
       "rec-1288-org    vanessa      parr           905       macquoid place   \n",
       "rec-3585-org    mikayla  malloney            37        randwick road   \n",
       "\n",
       "                      address_2            suburb postcode state  \\\n",
       "rec_id                                                             \n",
       "rec-1070-org              miami     winston hills     4223   nsw   \n",
       "rec-1016-org         bega flats         richlands     4560   vic   \n",
       "rec-4405-org               kela             dapto     4566   nsw   \n",
       "rec-1288-org  broadbridge manor     south grafton     2135    sa   \n",
       "rec-3585-org            avalind  hoppers crossing     4552   vic   \n",
       "\n",
       "             date_of_birth soc_sec_id  \n",
       "rec_id                                 \n",
       "rec-1070-org      19151111    5304218  \n",
       "rec-1016-org      19161214    4066625  \n",
       "rec-4405-org      19480930    4365168  \n",
       "rec-1288-org      19951119    9239102  \n",
       "rec-3585-org      19860208    7207688  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Preparation\n",
    "\n",
    "The linkage schema must be agreed on by the two parties. For this tutorial let's say that the only fields in common were Surname, First Name, Postcode, State, and Date of birth. We create a schema that ignores all other columns when creating CLKs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema written to /tmp/tmplqqn1v9k.yaml\n"
     ]
    }
   ],
   "source": [
    "column_metadata = [\n",
    "    'INDEX',\n",
    "    'NAME Surname',\n",
    "    'NAME First Name',\n",
    "    'INDEX',\n",
    "    'INDEX',\n",
    "    'INDEX',\n",
    "    'INDEX',\n",
    "    'ADDRESS POSTCODE',\n",
    "    'ADDRESS Place Name',\n",
    "    'DOB YYYY/MM/DD',\n",
    "    'INDEX'\n",
    "]\n",
    "\n",
    "schema = NamedTemporaryFile(\"wt\", suffix='.yaml')\n",
    "for col in column_metadata:\n",
    "    print('- identifier: \"{}\"'.format(col), file=schema)\n",
    "\n",
    "schema.seek(0)\n",
    "print(\"Schema written to\", schema.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Linkage Project\n",
    "\n",
    "The analyst carrying out the linkage starts by creating a linkage project of the desired output type with the Entity Service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials will be saved in /tmp/tmpf8dx1rwk\n",
      "\u001b[31mEntity Matching Server: https://es.data61.xyz\u001b[0m\n",
      "\u001b[31mChecking server status\u001b[0m\n",
      "\u001b[31mServer Status: ok\u001b[0m\n",
      "\u001b[31mSchema: [{\"identifier\": \"INDEX\"}, {\"identifier\": \"NAME Surname\"}, {\"identifier\": \"NAME First Name\"}, {\"identifier\": \"INDEX\"}, {\"identifier\": \"INDEX\"}, {\"identifier\": \"INDEX\"}, {\"identifier\": \"INDEX\"}, {\"identifier\": \"ADDRESS POSTCODE\"}, {\"identifier\": \"ADDRESS Place Name\"}, {\"identifier\": \"DOB YYYY/MM/DD\"}, {\"identifier\": \"INDEX\"}]\u001b[0m\n",
      "\u001b[31mType: permutation_unencrypted_mask\u001b[0m\n",
      "\u001b[31mCreating new mapping\u001b[0m\n",
      "\u001b[31mMapping created\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'resource_id': '4e82ce916a1ee6c3012f0a9a1c5c1ed46b62b08829583891',\n",
       " 'result_token': 'bb9f11216cdd39538f82576458cfb75ce984d48a12bed9fc',\n",
       " 'update_tokens': ['68d74f19523b09f7d600649c6b62454d51d7b41bd13c571b',\n",
       "  'cc29bcbcb4a296a596f91f4f99f514c116224e2ed69922c8']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creds = NamedTemporaryFile('wt')\n",
    "print(\"Credentials will be saved in\", creds.name)\n",
    "\n",
    "!clkutil create --schema \"{schema.name}\" --output \"{creds.name}\" --type \"permutation_unencrypted_mask\" --server \"{url}\" --threshold 0.85\n",
    "creds.seek(0)\n",
    "\n",
    "import json\n",
    "with open(creds.name, 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "mid = credentials['resource_id']\n",
    "credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the analyst will need to pass on the `resource_id` (the id of the linkage project) and one of the two `update_tokens` to each data provider.\n",
    "\n",
    "## Hash and Upload\n",
    "\n",
    "At the moment both data providers have *raw* personally identiy information. We first have to generate CLKs from the raw entity information. Please see [clkhash](https://clkhash.readthedocs.io/) documentation for further details on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating CLKs: 100%|█| 5.00K/5.00K [00:01<00:00, 1.95Kclk/s, mean=651, std=36.1]\n",
      "\u001b[31mCLK data written to /tmp/tmpyyyzbtl6.json\u001b[0m\n",
      "generating CLKs: 100%|█| 5.00K/5.00K [00:01<00:00, 1.07Kclk/s, mean=647, std=40.5]\n",
      "\u001b[31mCLK data written to /tmp/tmpf0rqxh20.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!clkutil hash --schema \"{schema.name}\" \"{a_csv.name}\" horse staple \"{a_clks.name}\"\n",
    "!clkutil hash --schema \"{schema.name}\" \"{b_csv.name}\" horse staple \"{b_clks.name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the two clients can upload their data providing the appropriate *upload tokens*. As with all commands in `clkhash` we can output help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: clkutil upload [OPTIONS] INPUT\n",
      "\n",
      "  Upload CLK data to entity matching server.\n",
      "\n",
      "  Given a json file containing hashed clk data as INPUT, upload to the\n",
      "  entity resolution service.\n",
      "\n",
      "  Use \"-\" to read from stdin.\n",
      "\n",
      "Options:\n",
      "  --mapping TEXT         Server identifier of the mapping\n",
      "  --apikey TEXT          Authentication API key for the server.\n",
      "  --server TEXT          Server address including protocol\n",
      "  -o, --output FILENAME\n",
      "  -v, --verbose          Script is more talkative\n",
      "  --help                 Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!clkutil upload --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice uploads her data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mUploading CLK data from /tmp/tmpyyyzbtl6.json\u001b[0m\n",
      "\u001b[31mTo Entity Matching Server: https://es.data61.xyz\u001b[0m\n",
      "\u001b[31mMapping ID: 4e82ce916a1ee6c3012f0a9a1c5c1ed46b62b08829583891\u001b[0m\n",
      "\u001b[31mChecking server status\u001b[0m\n",
      "\u001b[31mStatus: ok\u001b[0m\n",
      "\u001b[31mUploading CLK data to the server\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with NamedTemporaryFile('wt') as f:\n",
    "    !clkutil upload \\\n",
    "        --mapping=\"{credentials['resource_id']}\" \\\n",
    "        --apikey=\"{credentials['update_tokens'][0]}\" \\\n",
    "        --server \"{url}\" \\\n",
    "        --output \"{f.name}\" \\\n",
    "        \"{a_clks.name}\"\n",
    "    res = json.load(open(f.name))\n",
    "    alice_receipt_token = res['receipt-token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every upload gets a receipt token. In some operating modes this receipt is required to access the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bob uploads his data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mUploading CLK data from /tmp/tmpf0rqxh20.json\u001b[0m\n",
      "\u001b[31mTo Entity Matching Server: https://es.data61.xyz\u001b[0m\n",
      "\u001b[31mMapping ID: 4e82ce916a1ee6c3012f0a9a1c5c1ed46b62b08829583891\u001b[0m\n",
      "\u001b[31mChecking server status\u001b[0m\n",
      "\u001b[31mStatus: ok\u001b[0m\n",
      "\u001b[31mUploading CLK data to the server\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with NamedTemporaryFile('wt') as f:\n",
    "    !clkutil upload \\\n",
    "        --mapping=\"{credentials['resource_id']}\" \\\n",
    "        --apikey=\"{credentials['update_tokens'][1]}\" \\\n",
    "        --server \"{url}\" \\\n",
    "        --output \"{f.name}\" \\\n",
    "        \"{b_clks.name}\"\n",
    "    \n",
    "    bob_receipt_token = json.load(open(f.name))['receipt-token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now after some delay (depending on the size) we can fetch the mask.\n",
    "This can be done with clkutil:\n",
    "\n",
    "    !clkutil results \\\n",
    "        --mapping=\"{credentials['resource_id']}\" \\\n",
    "        --apikey=\"{credentials['result_token']}\" --output results.txt\n",
    "        \n",
    "However for this tutorial we are going to use the Python `requests` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ready': True,\n",
       " 'threshold': 0.85,\n",
       " 'time_added': '2018-03-27T10:24:40.346932',\n",
       " 'time_completed': '2018-03-27T10:24:50.005947',\n",
       " 'time_started': '2018-03-27T10:24:49.338349'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this cheeky cell is here to impose a small delay to allow the Entity Service to carry out the linkage when running the notebook automatically\n",
    "time.sleep(2)\n",
    "requests.get('{}/api/v1/mappings/{}/status'.format(url, mid), headers={'Authorization': credentials['result_token']}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = requests.get('{}/api/v1/mappings/{}'.format(url, mid), headers={'Authorization': credentials['result_token']})\n",
    "while result.status_code != 200:\n",
    "    print(result.json())\n",
    "    result = requests.get('{}/api/v1/mappings/{}'.format(url, mid), headers={'Authorization': credentials['result_token']})\n",
    "else:\n",
    "    results = result.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = results['mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mask is a boolean array that specifies where rows of permuted data line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 0, 1, 1, 1, 1, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(mask[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 1s in the mask will tell us how many matches were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4417"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for m in mask if m == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use `requests` to fetch the permutations for each data provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice_res = requests.get('{}/api/v1/mappings/{}'.format(url, mid), headers={'Authorization': alice_receipt_token}).json()\n",
    "bob_res = requests.get('{}/api/v1/mappings/{}'.format(url, mid), headers={'Authorization': bob_receipt_token}).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Alice and Bob both have a new permutation - a new ordering for their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[308, 4653, 3602, 439, 2287, 389, 4577, 1125, 4878, 158]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_permutation = alice_res['permutation']\n",
    "alice_permutation[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This permutation says the first row of Alice's data should be moved to position 308."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1651, 4849, 4530, 350, 4897, 3015, 2768, 4090, 4751, 1797]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_permutation = bob_res['permutation']\n",
    "bob_permutation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reorder(items, order):\n",
    "    \"\"\"\n",
    "    Assume order is a list of new index\n",
    "    \"\"\"\n",
    "    neworder = items.copy()\n",
    "    for item, newpos in zip(items, order):\n",
    "        neworder[newpos] = item\n",
    "    \n",
    "    return neworder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(a_csv.name, 'r') as f:\n",
    "    alice_raw = f.readlines()[1:]\n",
    "    alice_reordered = reorder(alice_raw, alice_permutation)\n",
    "\n",
    "with open(b_csv.name, 'r') as f:\n",
    "    bob_raw = f.readlines()[1:]\n",
    "    bob_reordered = reorder(bob_raw, bob_permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the two data sets have been permuted, the mask reveals where the rows line up, and where they don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec-2198-org,matilda,bergsma,73,macrobertson street,derry lodge,greensborough,2076,wa,19880213,5520743\\n',\n",
       " 'rec-4413-org,cameron,white,178,carlile street,laureldale,alice springs,6108,nsw,19470605,1655664\\n',\n",
       " 'rec-2064-org,jasper,miles,20,narryer close,moondah,nambour,4113,vic,19160130,3809763\\n',\n",
       " 'rec-4511-org,levi,oaks,38,courtice close,sunshine farm,findon,6050,wa,19101128,9317947\\n',\n",
       " 'rec-3659-org,alexander,vincent,51,gallagher street,top end,belmont,2333,qld,19150726,3732438\\n',\n",
       " 'rec-476-org,kyle,armiento,266,jaeger circuit,kookaburra village,springwood,7307,vic,19570728,3494623\\n',\n",
       " 'rec-998-org,bailey,green,76,jackie howe crescent,glengara village,murgon,3340,nsw,19960416,9882349\\n',\n",
       " 'rec-139-org,holly,rieman,3,heagney crescent,winter park,devonport,2546,qld,19751221,5260793\\n',\n",
       " 'rec-3071-org,charlie,walpole,43,lampard circuit,the meadows,alberton,2750,sa,19491212,5982948\\n',\n",
       " 'rec-2962-org,ethan,ryan,20,eaglemont retreat,melody cottage,camperdown,2615,nsw,19320524,2653664\\n']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_reordered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec-2198-dup-0,matilda,bergsma,73,macrobertson street,derrym lodge,greensborough,2076,wa,19880213,5520743\\n',\n",
       " 'rec-4413-dup-0,cameron,white,178,carliles treet,laureldale,harris park,6180,nsw,19470605,1655664\\n',\n",
       " 'rec-563-dup-0,sybella,meaney,82,julius street,east end,seafroth,3690,sa,,7466921\\n',\n",
       " 'rec-4511-dup-0,levi,oaks,38,courtice close,sunshin e farm,findon,6050,wa,19101128,9317947\\n',\n",
       " 'rec-3659-dup-0,ale xander,vincent,51,gallagher street,top end,belmont,2333,qld,19150726,3732438\\n',\n",
       " 'rec-476-dup-0,klye,armient o,266,jaegerc ircuit,kookabura village,elwood,7307,vic,19570728,3494623\\n',\n",
       " 'rec-998-dup-0,bailey,gree n,76,jackie howe crescent,glengara billage,murgon,3340,nsw,19960416,1468056\\n',\n",
       " 'rec-425-dup-0,psorakis,shantal,61,barcoo place,stonyridge,hawtnhorn,2324,vic,19850722,6633125\\n',\n",
       " 'rec-3071-dup-0,charlie,wakpbole,43,lampard circuit,the meadows,albertno,2750,sa,19260710,5982948\\n',\n",
       " 'rec-4496-dup-0,warnock,hark,,jansz cr escent,brentwood vlge,broadmeadows,2486,,19350219,7539077\\n']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_reordered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "To compute how well the matching went we will use the first index as our reference.\n",
    "\n",
    "For example in `rec-1396-org` is the original record which has a match in `rec-1396-dup-0`. To satisfy ourselves we can preview the first few supposed matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matilda Bergsma (rec-2198-org) =? Matilda Bergsma (rec-2198-dup-0)\n",
      "Cameron White (rec-4413-org) =? Cameron White (rec-4413-dup-0)\n",
      "Levi Oaks (rec-4511-org) =? Levi Oaks (rec-4511-dup-0)\n",
      "Alexander Vincent (rec-3659-org) =? Ale Xander Vincent (rec-3659-dup-0)\n",
      "Kyle Armiento (rec-476-org) =? Klye Armient O (rec-476-dup-0)\n",
      "Bailey Green (rec-998-org) =? Bailey Gree N (rec-998-dup-0)\n",
      "Charlie Walpole (rec-3071-org) =? Charlie Wakpbole (rec-3071-dup-0)\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(mask[:10]):\n",
    "    if m:\n",
    "        entity_a = alice_reordered[i].split(',')\n",
    "        entity_b = bob_reordered[i].split(',')\n",
    "        name_a = ' '.join(entity_a[1:3]).title()\n",
    "        name_b = ' '.join(entity_b[1:3]).title()\n",
    "        \n",
    "        print(\"{} ({})\".format(name_a, entity_a[0]), '=?', \"{} ({})\".format(name_b, entity_b[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "**Precision**: The percentage of actual matches out of all found matches. (`tp/(tp+fp)`)\n",
    "\n",
    "**Recall**: How many of the actual matches have we found? (`tp/(tp+fn)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4416 correct matches out of 5000. Incorrectly linked 1 matches.\n",
      "Precision: 100.0%\n",
      "Recall: 88.3%\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "\n",
    "for i, m in enumerate(mask):\n",
    "    if m:\n",
    "        entity_a = alice_reordered[i].split(',')\n",
    "        entity_b = bob_reordered[i].split(',')\n",
    "        if entity_a[0].split('-')[1] == entity_b[0].split('-')[1]:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            #print('False positive:',' '.join(entity_a[1:3]).title(), '?', ' '.join(entity_b[1:3]).title(), entity_a[-1] == entity_b[-1])\n",
    "\n",
    "print(\"Found {} correct matches out of 5000. Incorrectly linked {} matches.\".format(tp, fp))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/5000\n",
    "\n",
    "print(\"Precision: {:.1f}%\".format(100*precision))\n",
    "print(\"Recall: {:.1f}%\".format(100*recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
