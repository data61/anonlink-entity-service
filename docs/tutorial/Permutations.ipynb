{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Service Permutation Output\n",
    "\n",
    "This tutorial demonstrates generating CLKs from PII, creating a new project on the entity service, and how to retrieve the results. \n",
    "The output type is permutation and mask.\n",
    "\n",
    "The sections are usually run on different companies - but for illustration all is carried out in this one file. The participants providing data are *Alice* and *Bob*, and the analyst acting the integration authority.\n",
    "\n",
    "### Who learns what?\n",
    "\n",
    "Alice and Bob will both generate and upload their CLKs. After the linkage has been carried out they will be able to retrieve a `permutation` - a reordering of their respective data sets such that shared entities line up.\n",
    "\n",
    "The analyst - who creates the linkage project - learns the `mask`. The mask is a binary vector that indicates which rows in the permuted data sets are aligned. Note this reveals how many entities are shared.\n",
    "\n",
    "### Steps\n",
    "\n",
    "* Check connection to Entity Service\n",
    "* Data preparation\n",
    "  * Write CSV files with PII\n",
    "  * Create a Linkage Schema\n",
    "* Create Linkage Project\n",
    "* Generate CLKs from PII\n",
    "* Upload the PII\n",
    "* Create a run\n",
    "* Retrieve and analyse results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Connection\n",
    "\n",
    "If you are connecting to a custom entity service, change the address here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://testing.es.data61.xyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed',)).History will not be written to the database.\n",
      "{\"project_count\": 1412, \"rate\": 53129, \"status\": \"ok\"}\n"
     ]
    }
   ],
   "source": [
    "!clkutil status --server \"{url}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "Following the [clkhash tutorial](http://clkhash.readthedocs.io/en/latest/tutorial_cli.html) we will use a dataset from the `recordlinkage` library. We will just write both datasets out to temporary CSV files.\n",
    "\n",
    "If you are following along yourself you may have to adjust the file names in all the `!clkutil` commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import NamedTemporaryFile\n",
    "from recordlinkage.datasets import load_febrl4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets written to /tmp/tmp3kx41lxs and /tmp/tmpfiwx8pis\n"
     ]
    }
   ],
   "source": [
    "dfA, dfB = load_febrl4()\n",
    "\n",
    "a_csv = NamedTemporaryFile('w')\n",
    "a_clks = NamedTemporaryFile('w', suffix='.json')\n",
    "dfA.to_csv(a_csv)\n",
    "a_csv.seek(0)\n",
    "\n",
    "b_csv = NamedTemporaryFile('w')\n",
    "b_clks = NamedTemporaryFile('w', suffix='.json')\n",
    "dfB.to_csv(b_csv)\n",
    "b_csv.seek(0)\n",
    "\n",
    "dfA.head()\n",
    "print(\"Datasets written to {} and {}\".format(a_csv.name, b_csv.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>given_name</th>\n",
       "      <th>surname</th>\n",
       "      <th>street_number</th>\n",
       "      <th>address_1</th>\n",
       "      <th>address_2</th>\n",
       "      <th>suburb</th>\n",
       "      <th>postcode</th>\n",
       "      <th>state</th>\n",
       "      <th>date_of_birth</th>\n",
       "      <th>soc_sec_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rec-1070-org</th>\n",
       "      <td>michaela</td>\n",
       "      <td>neumann</td>\n",
       "      <td>8</td>\n",
       "      <td>stanley street</td>\n",
       "      <td>miami</td>\n",
       "      <td>winston hills</td>\n",
       "      <td>4223</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19151111</td>\n",
       "      <td>5304218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1016-org</th>\n",
       "      <td>courtney</td>\n",
       "      <td>painter</td>\n",
       "      <td>12</td>\n",
       "      <td>pinkerton circuit</td>\n",
       "      <td>bega flats</td>\n",
       "      <td>richlands</td>\n",
       "      <td>4560</td>\n",
       "      <td>vic</td>\n",
       "      <td>19161214</td>\n",
       "      <td>4066625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-4405-org</th>\n",
       "      <td>charles</td>\n",
       "      <td>green</td>\n",
       "      <td>38</td>\n",
       "      <td>salkauskas crescent</td>\n",
       "      <td>kela</td>\n",
       "      <td>dapto</td>\n",
       "      <td>4566</td>\n",
       "      <td>nsw</td>\n",
       "      <td>19480930</td>\n",
       "      <td>4365168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-1288-org</th>\n",
       "      <td>vanessa</td>\n",
       "      <td>parr</td>\n",
       "      <td>905</td>\n",
       "      <td>macquoid place</td>\n",
       "      <td>broadbridge manor</td>\n",
       "      <td>south grafton</td>\n",
       "      <td>2135</td>\n",
       "      <td>sa</td>\n",
       "      <td>19951119</td>\n",
       "      <td>9239102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rec-3585-org</th>\n",
       "      <td>mikayla</td>\n",
       "      <td>malloney</td>\n",
       "      <td>37</td>\n",
       "      <td>randwick road</td>\n",
       "      <td>avalind</td>\n",
       "      <td>hoppers crossing</td>\n",
       "      <td>4552</td>\n",
       "      <td>vic</td>\n",
       "      <td>19860208</td>\n",
       "      <td>7207688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             given_name   surname street_number            address_1  \\\n",
       "rec_id                                                                 \n",
       "rec-1070-org   michaela   neumann             8       stanley street   \n",
       "rec-1016-org   courtney   painter            12    pinkerton circuit   \n",
       "rec-4405-org    charles     green            38  salkauskas crescent   \n",
       "rec-1288-org    vanessa      parr           905       macquoid place   \n",
       "rec-3585-org    mikayla  malloney            37        randwick road   \n",
       "\n",
       "                      address_2            suburb postcode state  \\\n",
       "rec_id                                                             \n",
       "rec-1070-org              miami     winston hills     4223   nsw   \n",
       "rec-1016-org         bega flats         richlands     4560   vic   \n",
       "rec-4405-org               kela             dapto     4566   nsw   \n",
       "rec-1288-org  broadbridge manor     south grafton     2135    sa   \n",
       "rec-3585-org            avalind  hoppers crossing     4552   vic   \n",
       "\n",
       "             date_of_birth soc_sec_id  \n",
       "rec_id                                 \n",
       "rec-1070-org      19151111    5304218  \n",
       "rec-1016-org      19161214    4066625  \n",
       "rec-4405-org      19480930    4365168  \n",
       "rec-1288-org      19951119    9239102  \n",
       "rec-3585-org      19860208    7207688  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfA.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Schema Preparation\n",
    "\n",
    "The linkage schema must be agreed on by the two parties. A hashing schema instructs clkhash how to treat each column for generating CLKs. A detailed description of the hashing schema can be found in the api docs. We will ignore the columns ‘rec_id’ and ‘soc_sec_id’ for CLK generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = NamedTemporaryFile('wt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /tmp/tmp8kzi4os5\n"
     ]
    }
   ],
   "source": [
    "%%writefile {schema.name}\n",
    "{\n",
    "  \"version\": 1,\n",
    "  \"clkConfig\": {\n",
    "    \"l\": 1024,\n",
    "    \"k\": 30,\n",
    "    \"hash\": {\n",
    "      \"type\": \"doubleHash\"\n",
    "    },\n",
    "    \"kdf\": {\n",
    "      \"type\": \"HKDF\",\n",
    "      \"hash\": \"SHA256\",\n",
    "        \"info\": \"c2NoZW1hX2V4YW1wbGU=\",\n",
    "        \"salt\": \"SCbL2zHNnmsckfzchsNkZY9XoHk96P/G5nUBrM7ybymlEFsMV6PAeDZCNp3rfNUPCtLDMOGQHG4pCQpfhiHCyA==\",\n",
    "        \"keySize\": 64\n",
    "    }\n",
    "  },\n",
    "  \"features\": [\n",
    "    {\n",
    "      \"identifier\": \"rec_id\",\n",
    "      \"ignored\": true\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"given_name\",\n",
    "      \"format\": { \"type\": \"string\", \"encoding\": \"utf-8\" },\n",
    "      \"hashing\": { \"ngram\": 2, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"surname\",\n",
    "      \"format\": { \"type\": \"string\", \"encoding\": \"utf-8\" },\n",
    "      \"hashing\": { \"ngram\": 2, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"street_number\",\n",
    "      \"format\": { \"type\": \"integer\" },\n",
    "      \"hashing\": { \"ngram\": 1, \"positional\": true, \"weight\": 1, \"missingValue\": {\"sentinel\": \"\"} }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"address_1\",\n",
    "      \"format\": { \"type\": \"string\", \"encoding\": \"utf-8\" },\n",
    "      \"hashing\": { \"ngram\": 2, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"address_2\",\n",
    "      \"format\": { \"type\": \"string\", \"encoding\": \"utf-8\" },\n",
    "      \"hashing\": { \"ngram\": 2, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"suburb\",\n",
    "      \"format\": { \"type\": \"string\", \"encoding\": \"utf-8\" },\n",
    "      \"hashing\": { \"ngram\": 2, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"postcode\",\n",
    "      \"format\": { \"type\": \"integer\", \"minimum\": 100, \"maximum\": 9999 },\n",
    "      \"hashing\": { \"ngram\": 1, \"positional\": true, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"state\",\n",
    "      \"format\": { \"type\": \"string\", \"encoding\": \"utf-8\", \"maxLength\": 3 },\n",
    "      \"hashing\": { \"ngram\": 2, \"weight\": 1 }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"date_of_birth\",\n",
    "      \"format\": { \"type\": \"integer\" },\n",
    "      \"hashing\": { \"ngram\": 1, \"positional\": true, \"weight\": 1, \"missingValue\": {\"sentinel\": \"\"} }\n",
    "    },\n",
    "    {\n",
    "      \"identifier\": \"soc_sec_id\",\n",
    "      \"ignored\": true\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Linkage Project\n",
    "\n",
    "The analyst carrying out the linkage starts by creating a linkage project of the desired output type with the Entity Service.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials will be saved in /tmp/tmpp2qwgwlz\n",
      "\u001b[31mProject created\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'project_id': '432e0100559b4341aa474d62339a3a8f3a7d2b4db816e316',\n",
       " 'result_token': 'da272f18ae832a21df064b8815d47f74e28da5e4b776c7d8',\n",
       " 'update_tokens': ['a042146986db4d57824db09ad9bf1019093037f72d7395cf',\n",
       "  '9a3896d90b57cd873b5e3408ef3774fc19dceb15a8b879aa']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "creds = NamedTemporaryFile('wt')\n",
    "print(\"Credentials will be saved in\", creds.name)\n",
    "\n",
    "!clkutil create-project --schema \"{schema.name}\" --output \"{creds.name}\" --type \"permutations\" --server \"{url}\"\n",
    "creds.seek(0)\n",
    "\n",
    "import json\n",
    "with open(creds.name, 'r') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "project_id = credentials['project_id']\n",
    "credentials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** the analyst will need to pass on the `project_id` (the id of the linkage project) and one of the two `update_tokens` to each data provider.\n",
    "\n",
    "## Hash and Upload\n",
    "\n",
    "At the moment both data providers have *raw* personally identiy information. We first have to generate CLKs from the raw entity information. Please see [clkhash](https://clkhash.readthedocs.io/) documentation for further details on this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating CLKs: 100%|█| 5.00k/5.00k [00:03<00:00, 1.22kclk/s, mean=883, std=33.6]\n",
      "\u001b[31mCLK data written to /tmp/tmpgufu8og6.json\u001b[0m\n",
      "generating CLKs: 100%|█| 5.00k/5.00k [00:02<00:00, 524clk/s, mean=875, std=39.7]\n",
      "\u001b[31mCLK data written to /tmp/tmpjx0otna1.json\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!clkutil hash \"{a_csv.name}\" horse staple \"{schema.name}\" \"{a_clks.name}\"\n",
    "!clkutil hash \"{b_csv.name}\" horse staple \"{schema.name}\" \"{b_clks.name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the two clients can upload their data providing the appropriate *upload tokens*. As with all commands in `clkhash` we can output help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: clkutil upload [OPTIONS] INPUT\n",
      "\n",
      "  Upload CLK data to entity matching server.\n",
      "\n",
      "  Given a json file containing hashed clk data as INPUT, upload to the\n",
      "  entity resolution service.\n",
      "\n",
      "  Use \"-\" to read from stdin.\n",
      "\n",
      "Options:\n",
      "  --project TEXT         Project identifier\n",
      "  --apikey TEXT          Authentication API key for the server.\n",
      "  --server TEXT          Server address including protocol\n",
      "  -o, --output FILENAME\n",
      "  -v, --verbose          Script is more talkative\n",
      "  --help                 Show this message and exit.\n"
     ]
    }
   ],
   "source": [
    "!clkutil upload --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alice uploads her data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with NamedTemporaryFile('wt') as f:\n",
    "    !clkutil upload \\\n",
    "        --project=\"{project_id}\" \\\n",
    "        --apikey=\"{credentials['update_tokens'][0]}\" \\\n",
    "        --server \"{url}\" \\\n",
    "        --output \"{f.name}\" \\\n",
    "        \"{a_clks.name}\"\n",
    "    res = json.load(open(f.name))\n",
    "    alice_receipt_token = res['receipt_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every upload gets a receipt token. In some operating modes this receipt is required to access the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bob uploads his data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NamedTemporaryFile('wt') as f:\n",
    "    !clkutil upload \\\n",
    "        --project=\"{project_id}\" \\\n",
    "        --apikey=\"{credentials['update_tokens'][1]}\" \\\n",
    "        --server \"{url}\" \\\n",
    "        --output \"{f.name}\" \\\n",
    "        \"{b_clks.name}\"\n",
    "    \n",
    "    bob_receipt_token = json.load(open(f.name))['receipt_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a run\n",
    "\n",
    "Now the project has been created and the CLK data has been uploaded we can carry out some privacy preserving record linkage. Try with a few different threshold values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with NamedTemporaryFile('wt') as f:\n",
    "    !clkutil create \\\n",
    "        --project=\"{project_id}\" \\\n",
    "        --apikey=\"{credentials['result_token']}\" \\\n",
    "        --server \"{url}\" \\\n",
    "        --threshold 0.9 \\\n",
    "        --output \"{f.name}\"\n",
    "    \n",
    "    run_id = json.load(open(f.name))['run_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Now after some delay (depending on the size) we can fetch the mask.\n",
    "This can be done with clkutil:\n",
    "\n",
    "    !clkutil results --server \"{url}\" \\\n",
    "        --project=\"{credentials['project_id']}\" \\\n",
    "        --apikey=\"{credentials['result_token']}\" --output results.txt\n",
    "        \n",
    "However for this tutorial we are going to use the Python `requests` library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import clkhash.rest_client\n",
    "import json\n",
    "import time\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State: completed\n",
      "Stage (3/3): compute output\n"
     ]
    }
   ],
   "source": [
    "for update in clkhash.rest_client.watch_run_status(url, project_id, run_id, credentials['result_token'], timeout=300):\n",
    "    clear_output(wait=True)\n",
    "    print(clkhash.rest_client.format_run_status(update))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = requests.get('{}/api/v1/projects/{}/runs/{}/result'.format(url, project_id, run_id), headers={'Authorization': credentials['result_token']}).json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = results['mask']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This mask is a boolean array that specifies where rows of permuted data line up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(mask[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of 1s in the mask will tell us how many matches were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([1 for m in mask if m == 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use `requests` to fetch the permutations for each data provider:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alice_res = requests.get('{}/api/v1/projects/{}/runs/{}/result'.format(url, project_id, run_id), headers={'Authorization': alice_receipt_token}).json()\n",
    "bob_res = requests.get('{}/api/v1/projects/{}/runs/{}/result'.format(url, project_id, run_id), headers={'Authorization': bob_receipt_token}).json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now Alice and Bob both have a new permutation - a new ordering for their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3074, 2978, 827, 4760, 4501, 2399, 2546, 235, 4126, 2618]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_permutation = alice_res['permutation']\n",
    "alice_permutation[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This permutation says the first row of Alice's data should be moved to position 308."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2046, 4958, 662, 4681, 4129, 3674, 4663, 3117, 2148, 4336]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_permutation = bob_res['permutation']\n",
    "bob_permutation[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reorder(items, order):\n",
    "    \"\"\"\n",
    "    Assume order is a list of new index\n",
    "    \"\"\"\n",
    "    neworder = items.copy()\n",
    "    for item, newpos in zip(items, order):\n",
    "        neworder[newpos] = item\n",
    "    \n",
    "    return neworder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(a_csv.name, 'r') as f:\n",
    "    alice_raw = f.readlines()[1:]\n",
    "    alice_reordered = reorder(alice_raw, alice_permutation)\n",
    "\n",
    "with open(b_csv.name, 'r') as f:\n",
    "    bob_raw = f.readlines()[1:]\n",
    "    bob_reordered = reorder(bob_raw, bob_permutation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the two data sets have been permuted, the mask reveals where the rows line up, and where they don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec-2015-org,arabella,sorsa,29,corringle close,mari-ma farm,mulgrave east,4871,qld,19450119,2313601\\n',\n",
       " 'rec-4927-org,daniel,glass,8,roe street,rowethorpe,williamstown,2026,tas,19170309,4569679\\n',\n",
       " 'rec-3783-org,alannah,newport,7,wakefield avenue,glenmore,moree,4662,qld,19401219,4895884\\n',\n",
       " 'rec-4812-org,anthony,roche,11,waller crescent,gungarlin,inglewood,3103,act,19930109,7209435\\n',\n",
       " \"rec-1448-org,teal,donaldson,,o'sullivan street,willow lodge,springwood,7030,nsw,19241229,8492921\\n\",\n",
       " 'rec-489-org,brandon,strangway,177,robert campbell road,dryrock gulch,toowoomba,4121,nsw,19220610,4691109\\n',\n",
       " 'rec-4403-org,harriet,paterson,5,smiths road,jaybees,ringwood east,6012,nsw,19321027,3012880\\n',\n",
       " 'rec-328-org,ronan,zatorski,13,lott place,bobblegigbie,ringwood east,5109,qld,19870107,5925683\\n',\n",
       " 'rec-2518-org,makayla,thoonen,119,tullaroop street,rosetta village,byford,3977,vic,19750818,1423820\\n',\n",
       " 'rec-2323-org,rachael,yallop,15,fullagar crescent,rsde 668,beenleigh,4860,qld,19760214,1296128\\n']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alice_reordered[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rec-2015-dup-0,arabella,sors,92,corringle close,mari-ma farm,mulgrave east,4871,qld,19450119,2313601\\n',\n",
       " 'rec-4927-dup-0,daniel,glad,,roe street,rowethorpe,tungamull,2026,tas,19170309,4569679\\n',\n",
       " 'rec-3783-dup-0,katelyn,newport,7,wakefield avenue,glenmore,moree,4662,qld,19401219,4895884\\n',\n",
       " 'rec-4812-dup-0,anthony,roche,11,waller ceescent,gungarlin,st andrews,3103,act,19930109,7209435\\n',\n",
       " \"rec-1448-dup-0,tea,donaklsdon,,o'sullivan street,willow lodge,springwood,7030,nsw,19891118,8492921\\n\",\n",
       " 'rec-489-dup-0,brandon,strangway,177,everard lace,dryroc k gulch,hinchinbrook,4121,nsw,19220610,4691109\\n',\n",
       " 'rec-4403-dup-0,harriet,paterson,5,smiths road,jaybees,ringwood past,6012,nsw,19321027,3012880\\n',\n",
       " 'rec-328-dup-0,ronan,zatorski,13,lott place,bobblegigbie,ringwoo east,5109,qld,19870107,5925683\\n',\n",
       " 'rec-2518-dup-0,thoonen,makayla,119,tullaroop street,rosetta village,byford,3977,vic,19750818,1423820\\n',\n",
       " 'rec-2323-dup-0,rachael,yallop,5,fullagar crescent,rsde 668,been leigh,4860,qld,19760214,1296128\\n']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bob_reordered[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy\n",
    "\n",
    "To compute how well the matching went we will use the first index as our reference.\n",
    "\n",
    "For example in `rec-1396-org` is the original record which has a match in `rec-1396-dup-0`. To satisfy ourselves we can preview the first few supposed matches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arabella Sorsa (rec-2015-org) =? Arabella Sors (rec-2015-dup-0)\n",
      "Daniel Glass (rec-4927-org) =? Daniel Glad (rec-4927-dup-0)\n",
      "Alannah Newport (rec-3783-org) =? Katelyn Newport (rec-3783-dup-0)\n",
      "Anthony Roche (rec-4812-org) =? Anthony Roche (rec-4812-dup-0)\n",
      "Teal Donaldson (rec-1448-org) =? Tea Donaklsdon (rec-1448-dup-0)\n",
      "Brandon Strangway (rec-489-org) =? Brandon Strangway (rec-489-dup-0)\n",
      "Harriet Paterson (rec-4403-org) =? Harriet Paterson (rec-4403-dup-0)\n",
      "Ronan Zatorski (rec-328-org) =? Ronan Zatorski (rec-328-dup-0)\n",
      "Makayla Thoonen (rec-2518-org) =? Thoonen Makayla (rec-2518-dup-0)\n",
      "Rachael Yallop (rec-2323-org) =? Rachael Yallop (rec-2323-dup-0)\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(mask[:10]):\n",
    "    if m:\n",
    "        entity_a = alice_reordered[i].split(',')\n",
    "        entity_b = bob_reordered[i].split(',')\n",
    "        name_a = ' '.join(entity_a[1:3]).title()\n",
    "        name_b = ' '.join(entity_b[1:3]).title()\n",
    "        \n",
    "        print(\"{} ({})\".format(name_a, entity_a[0]), '=?', \"{} ({})\".format(name_b, entity_b[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "**Precision**: The percentage of actual matches out of all found matches. (`tp/(tp+fp)`)\n",
    "\n",
    "**Recall**: How many of the actual matches have we found? (`tp/(tp+fn)`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4447 correct matches out of 5000. Incorrectly linked 383 matches.\n",
      "Precision: 92.1%\n",
      "Recall: 88.9%\n"
     ]
    }
   ],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "\n",
    "for i, m in enumerate(mask):\n",
    "    if m:\n",
    "        entity_a = alice_reordered[i].split(',')\n",
    "        entity_b = bob_reordered[i].split(',')\n",
    "        if entity_a[0].split('-')[1] == entity_b[0].split('-')[1]:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "            #print('False positive:',' '.join(entity_a[1:3]).title(), '?', ' '.join(entity_b[1:3]).title(), entity_a[-1] == entity_b[-1])\n",
    "\n",
    "print(\"Found {} correct matches out of 5000. Incorrectly linked {} matches.\".format(tp, fp))\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/5000\n",
    "\n",
    "print(\"Precision: {:.1f}%\".format(100*precision))\n",
    "print(\"Recall: {:.1f}%\".format(100*recall))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
