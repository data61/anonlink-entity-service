{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import os\n",
    "\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Entity Service: Multiparty linkage demo\n",
    "This notebook is a demonstration of the multiparty linkage capability that has been implemented in the Entity Service.\n",
    "\n",
    "We show how five parties may upload their hashed data to the Entity Service to obtain a multiparty linkage result. This result identifies each entity across all datasets in which they are included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Check the status of the Entity Service\n",
    "Ensure that it is running and that we have the correct version. Multiparty support was introduced in version 1.11.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'project_count': 0, 'rate': 1, 'status': 'ok'}\n",
      "{'anonlink': '0.11.2', 'entityservice': 'v1.11.0', 'python': '3.6.8'}\n"
     ]
    }
   ],
   "source": [
    "PREFIX = \"http://localhost:8851/api/v1\"\n",
    "print(requests.get(f\"{PREFIX}/status\").json())\n",
    "print(requests.get(f\"{PREFIX}/version\").json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Create a new project\n",
    "We create a new multiparty project for five parties by specifying the number of parties and the output type (currently only the `group` output type supports multiparty linkage). Retain the `project_id`, so we can find the project later. Also retain the `result_token`, so we can retrieve the results (careful: anyone with this token has access to the results). Finally, the `update_tokens` identify the five data data providers and permit them to upload CLKs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_id: bf373054ee0ed0cd5698dbc43b36c87744b134993ecb843d\n",
      "\n",
      "result_token: 6684ab2f06587ca3079d02651c8265c1b35f3be8e8fe238e\n",
      "\n",
      "update_tokens: ['d2c1084f091b7d31d2dc1d18b42570e78f8697bb912dfde0', 'a762cebc30701bf860c7186aec940e8b303f272ddb991398', 'dd079d56422dc0c295f6c93df5e25e2e91ba3d01cdd66aa4', '50d25349d8a4d3a9e81c55ab2cb92fc765f0091b035e60ff', '714af297548d14693a9ffb1e598567f9900a754c8b6c89e7']\n"
     ]
    }
   ],
   "source": [
    "project_info = requests.post(\n",
    "    f\"{PREFIX}/projects\",\n",
    "    json={\n",
    "        \"schema\": {},\n",
    "        \"result_type\": \"groups\",\n",
    "        \"number_parties\": 5,\n",
    "        \"name\": \"example project\"\n",
    "    }\n",
    ").json()\n",
    "project_id = project_info[\"project_id\"]\n",
    "result_token = project_info[\"result_token\"]\n",
    "update_tokens = project_info[\"update_tokens\"]\n",
    "\n",
    "print(\"project_id:\", project_id)\n",
    "print()\n",
    "print(\"result_token:\", result_token)\n",
    "print()\n",
    "print(\"update_tokens:\", update_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Upload the hashed data\n",
    "This is where each party uploads their CLKs into the service. Here, we do the work of all five data providers inside this for loop. In a deployment scenario, each data provider would be uploading their own CLKs using their own update token.\n",
    "\n",
    "These CLKs are already hashed using [clkhash](https://github.com/data61/clkhash), so for each data provider, we just need to upload their corresponding hash file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data provider 1: {\n",
      "  \"message\": \"Updated\",\n",
      "  \"receipt_token\": \"795739e4d364fbbc35b9975c7e751f864ef372cd6ede2c5c\"\n",
      "}\n",
      "\n",
      "Data provider 2: {\n",
      "  \"message\": \"Updated\",\n",
      "  \"receipt_token\": \"446be8109f13ffb58a87f526c77badb8c705f1cb1cd062cd\"\n",
      "}\n",
      "\n",
      "Data provider 3: {\n",
      "  \"message\": \"Updated\",\n",
      "  \"receipt_token\": \"503eeaa96883aaa4dd78ad1671a4ba158f476673564d2783\"\n",
      "}\n",
      "\n",
      "Data provider 4: {\n",
      "  \"message\": \"Updated\",\n",
      "  \"receipt_token\": \"3cb842a5cdcfcc19410204cd141dcd90609701ff066f3c73\"\n",
      "}\n",
      "\n",
      "Data provider 5: {\n",
      "  \"message\": \"Updated\",\n",
      "  \"receipt_token\": \"49cc67666c200db6db642a18f3dcd74debbca1a4d079d938\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, token in enumerate(update_tokens, start=1):\n",
    "    with open(f\"data/clks-{i}.json\") as f:\n",
    "        r = requests.post(\n",
    "            f\"{PREFIX}/projects/{project_id}/clks\",\n",
    "            data=f,\n",
    "            headers={\n",
    "                \"Authorization\": token,\n",
    "                \"content-type\": \"application/json\"\n",
    "            }\n",
    "        )\n",
    "    print(f\"Data provider {i}: {r.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Begin a run\n",
    "The data providers have uploaded their CLKs, so we may begin the computation. This computation may be repeated multiple times, each time with different parameters. Each such repetition is called a run. The most important parameter to vary between runs is the similarity threshold. Two records whose similarity is above this threshold will be considered to describe the same entity.\n",
    "\n",
    "Here, we perform one run. We (somewhat arbitrarily) choose the threshold to be 0.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "r = requests.post(\n",
    "    f\"{PREFIX}/projects/{project_id}/runs\",\n",
    "    headers={\n",
    "        \"Authorization\": result_token\n",
    "    },\n",
    "    json={\n",
    "        \"threshold\": 0.8\n",
    "    }\n",
    ")\n",
    "run_id = r.json()[\"run_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Check the status\n",
    "Let's see whether the run has finished ('state' is 'completed')!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'current_stage': {'description': 'compute output', 'number': 3},\n",
       " 'stages': 3,\n",
       " 'state': 'completed',\n",
       " 'time_added': '2019-06-17T04:48:35.415224+00:00',\n",
       " 'time_completed': '2019-06-17T04:48:55.962677+00:00',\n",
       " 'time_started': '2019-06-17T04:48:36.826288+00:00'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\n",
    "    f\"{PREFIX}/projects/{project_id}/runs/{run_id}/status\",\n",
    "    headers={\n",
    "        \"Authorization\": result_token\n",
    "    }\n",
    ")\n",
    "r.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Retrieve the results\n",
    "We retrieve the results of the linkage. As we selected earlier, the result is a list of groups of records. Every record in such a group belongs to the same entity and consists of two values, the party id and the row index.\n",
    "\n",
    "The last 20 groups look like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1, 1884], [2, 1911], [4, 1926], [0, 1916]],\n",
       " [[2, 3173], [4, 3176], [3, 3163], [0, 3145], [1, 3161]],\n",
       " [[0, 444], [1, 423]],\n",
       " [[0, 1206], [4, 1205], [2, 1206]],\n",
       " [[1, 797], [3, 823], [2, 833], [0, 813]],\n",
       " [[0, 741], [3, 752]],\n",
       " [[0, 1902], [4, 1911], [1, 1868], [3, 1895], [2, 1899]],\n",
       " [[3, 2833], [4, 2837], [1, 2842]],\n",
       " [[2, 1631], [3, 1631]],\n",
       " [[0, 143], [1, 142], [4, 121]],\n",
       " [[0, 1912], [4, 3137]],\n",
       " [[2, 538], [3, 542]],\n",
       " [[2, 2196], [3, 2189], [4, 2190], [1, 2188]],\n",
       " [[0, 105], [3, 83], [1, 107]],\n",
       " [[1, 2526], [2, 2545], [4, 2516]],\n",
       " [[3, 1140], [4, 837]],\n",
       " [[0, 3175], [1, 3192], [4, 3204]],\n",
       " [[3, 1055], [4, 1064], [2, 1074], [1, 1021]],\n",
       " [[0, 2009], [2, 2003]],\n",
       " [[1, 848], [4, 871], [3, 880]]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = requests.get(\n",
    "    f\"{PREFIX}/projects/{project_id}/runs/{run_id}/result\",\n",
    "    headers={\n",
    "        \"Authorization\": result_token\n",
    "    }\n",
    ")\n",
    "groups = r.json()\n",
    "groups['groups'][-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To sanity check, we pick the first 20 groups and print their records' corresponding PII."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ['georgia', 'nguyen', '06-11-1930', 'male', 'perth', '247847.799', '08 6560 4063']\n",
      "2 ['georia', 'nfuyen', '06-11-1930', 'male', 'perrh', '247847.799', '08 6560 4963']\n",
      "4 ['geortia', 'nguyea', '06-11-1930', 'male', 'pertb', '247847.798', '08 6560 4063']\n",
      "0 ['egorgia', 'nguyqn', '06-11-1930', 'male', 'peryh', '247847.799', '08 6460 4963']\n",
      "\n",
      "2 ['harriyon', 'micyelmor', '21-04-1971', 'male', 'pert1>', '291889.942', '04 5633 5749']\n",
      "4 ['harri5on', 'micyelkore', '21-04-1971', '', 'pertb', '291880.942', '04 5633 5749']\n",
      "3 ['hariso17', 'micelmore', '21-04-1971', 'male', 'pertb', '291880.042', '04 5633 5749']\n",
      "0 ['harrison', 'michelmore', '21-04-1981', 'malw', 'preth', '291880.942', '04 5643 5749']\n",
      "1 ['harris0n', 'michelmoer', '21-04-1971', '', '', '291880.942', '04 5633 5749']\n",
      "\n",
      "0 ['joshai', 'browne', '30-10-2904', '', 'melbounfe', '522585.205', '03 7150 7587']\n",
      "1 ['joshua', 'browne', '30-10-2004', 'female', 'melbourne', '522585.205', '03 7150 7587']\n",
      "\n",
      "0 ['james', 'lavender', '08-02-2000', 'male', 'canberra', '88844.369', '02 5862 9827']\n",
      "4 ['jaiiies', 'lvender', '08-02-2900', 'male', 'canberra', '88844.369', '02 5862 982u']\n",
      "2 ['jimmy', 'lavendre', '08-02-2000', 'malw', 'canberra', '88844.369', '02 5863 9827']\n",
      "\n",
      "1 ['mitchel', 'white', '10-99-1913', 'mals', 'melbourne', '106397.027', '07 6224 1278']\n",
      "3 ['mitchell', 'white', '10-09-1913', 'male', 'melbourne', '106307.027', '07 6224 1278']\n",
      "2 ['mitchelk', 'whitw', '10-09-1913', 'mqle', 'melbourne', '106307.037', '07 6224 1278']\n",
      "0 ['mitxell', 'white', '10-09-2924', '', 'melourne', '106307.027', '07 6224 1278']\n",
      "\n",
      "0 ['molly', 'locge', '', 'male', 'emlbovrne', '168663.495', '']\n",
      "3 ['mvolly', 'lodge', '', 'malr', 'melbourne', '168663.495', '']\n",
      "\n",
      "0 ['ellax', 'etherington', '20-08-1923', 'mal3', 'canberra', '', '03 9453 3904']\n",
      "4 ['ella', 'etherington', '20-08-1923', 'male', 'canberra', '54326.777', '03 9454 3904']\n",
      "1 ['ella', 'etherinqton', '20-08-1923', 'maoe', 'canherra', '54326.776', '03 9454 3904']\n",
      "3 ['ela', 'etheringotn', '20-08-1923', 'malr', 'canloerra', '54326.777', '03 9454 3904']\n",
      "2 ['ella', 'eterington', '20-08-1023', 'male', 'canberrpa', '54326.777', '03 9454 3804']\n",
      "\n",
      "3 ['arki', 'mselwee', '01-08-1969', 'make', '', '167384.597', '08 2573 8539']\n",
      "4 ['aahki', 'mcelwee', '01-08-1969', 'maoe', '', '167384.697', '08 2574 8539']\n",
      "1 ['arki', 'mcelvvee', '01-08-1969', 'male', '', '', '08 2574 8549']\n",
      "\n",
      "2 ['mateoe:ne', 'maedow5', '27-05-1980', 'maoe', '', '24875.834', '07 6388 4121']\n",
      "3 ['madele:ne', 'maedosw', '27-05-2980', 'male', '', '24875.834', '07 6388 4121']\n",
      "\n",
      "0 ['sarah', 'thorps', '22-05-1944', '', 'melnourne', '196834.197', '02 9511 1457']\n",
      "1 ['sarah', 'thorpe', '22-05-1944', 'male', 'melbourne', '196834.297', '02 9511 1457']\n",
      "4 ['sarah', 'zhorpe', '22-05-1944', 'male', 'meobpurne', '', '02 9612 1457']\n",
      "\n",
      "0 ['isabella', 'george', '13-09-1920', 'male', 'melbourne', '39385.412', '08 0025 2199']\n",
      "4 ['isabella', 'george', '14-04-1907', 'male', 'melbourne', '157866.260', '04 6230 3726']\n",
      "\n",
      "2 ['jordam', 'hyes', '06-03-1978', 'female', 'melboume', '931637.600', '']\n",
      "3 ['joahdan', 'hetes', '06-03-2978', 'female', 'melbourne', '931637.600', '']\n",
      "\n",
      "2 ['des:', 'cochrame', '25-07-1902', '', 'melbourne', '175000.123', '02 2669 0150']\n",
      "3 ['desi', 'cochrane', '25-07-1902', 'male', 'melbourne', '175000.122', '02 2669 0150']\n",
      "4 ['des:', 'cochrane', '25-07-1902', 'mals', 'melbornte', '', '02 2669 0150']\n",
      "1 ['des:', 'cocyrane', '25-07-1902', 'male', '', '175000.122', '02 2769 0150']\n",
      "\n",
      "0 ['georgua', 'matthews', '08-05-2908', 'female', 'sydnry', '153080.431', '07 8220 6300']\n",
      "3 ['georgia', 'matthewj', '08-05-1998', 'female', 'syfney', '153090.422', '07 8220 7300']\n",
      "1 ['georgja', 'matthwws', '08-05-1998', 'female', 'sydnev', '153090.431', '']\n",
      "\n",
      "1 ['jade', 'curry', '21-08-1979', 'female', 'melbourne', '1027298.741', '07 1224 9461']\n",
      "2 ['jad', 'curry', '21-08-1879', 'femal4', 'melbournc', '1027298.741', '07 1224 9461']\n",
      "4 ['jat', 'currv', '21-08-1979', 'female', 'meloburne', '1027298.741', '08 1224 9461']\n",
      "\n",
      "3 ['mia', 'galbraith', '06-02-1982', 'female', 'sydney', '100235.971', '03 8494 2792']\n",
      "4 ['talia', 'galbraith', '05-07-1960', 'female', 'sydney', '199837.956', '03 0962 3001']\n",
      "\n",
      "0 ['xanthe', 'white', '07-02-1966', 'male', 'melbourne', '133693.344', '08 4887 5960']\n",
      "1 ['anthe', 'hite', '07-02-1966', 'male', 'melgourne', '133693.344', '08 4877 5960']\n",
      "4 ['xanyh', 'whide', '07-02-1066', 'male', 'melbourne', '133603.344', '08 4887 5960']\n",
      "\n",
      "3 ['samantha', 'eyrr', '11-06-1950', 'femals', 'canberra', '31299.004', '07 0386 9783']\n",
      "4 ['samantha', 'eyre', '11-05-1950', 'female', 'canberra', '31299.004', '07 0396 9783']\n",
      "2 ['samantha', 'eyfe', '11-05-1950', 'femalw', 'ca17berra', '31299.004', '07 0396 9683']\n",
      "1 ['sam', 'yre', '11-05-1950', 'fenale', 'canberra', '31299.004', '07 0396 8783']\n",
      "\n",
      "0 ['lucy', 'rees', '11-02-1946', 'male', 'melbourne', '141567.031', '07 7956 5026']\n",
      "2 ['lucy', 'reea', '11-02-1946', 'make', '', '141567.031', '07 7956 5926']\n",
      "\n",
      "1 ['gialn', 'clarke', '21-08-1920', 'male', 'camberra', '77271.391', '07 1610 3387']\n",
      "4 ['giaan', 'klarke', '21-08-q920', 'male', 'amberra', '76271.391', '07 1520 3387']\n",
      "3 ['igan', 'clarke', '21-08-1020', 'male', 'acmberra', '76271.381', '07 1620 3387']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(i):\n",
    "    dataset = []\n",
    "    with open(f\"data/dataset-{i}.csv\") as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)  # ignore header\n",
    "        for row in reader:\n",
    "            dataset.append(row[1:])\n",
    "    return dataset\n",
    "\n",
    "datasets = list(map(load_dataset, range(1,6)))\n",
    "\n",
    "for group in itertools.islice(groups[\"groups\"][-20], 20):\n",
    "    for i, j in group:\n",
    "        print(i, datasets[i][j])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "Despite the high amount of noise in the data, the entity service was able to produce a fairly accurate matching. However, Isabella George and Mia/Talia Galbraith are most likely not an actual match.\n",
    "\n",
    "We may be able to improve on this results by fine-tuning the hashing schema or by changing the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Delete the project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204\n"
     ]
    }
   ],
   "source": [
    "r = requests.delete(\n",
    "    f\"{PREFIX}/projects/{project_id}\",\n",
    "    headers={\n",
    "        \"Authorization\": result_token\n",
    "    }\n",
    ")\n",
    "print(r.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
