Name: "entityservice"

api:
  ingress:
    enabled: true
  domain: "es.data61.xyz"
  domainProvider: "route53"

  imageRegistery: "quay.io/n1analytics"

  ## "IfNotPresent" or "Always"
  imagePullPolicy: "IfNotPresent"

  ## Expose the service to be accessed from outside the cluster (LoadBalancer service).
  ## or access it from within the cluster (ClusterIP service).
  ## Set the service type and the port to serve it.
  ## ref: http://kubernetes.io/docs/user-guide/services/
  ## Most likely if ingress is enabled, this should be ClusterIP,
  ## Otherwise LoadBalancer. Note you should manually adjust the timeout on
  ## an AWS ELB to 300+ seconds (from the default of 60).
  serviceType: "ClusterIP"
  servicePort: 80

  ## If using a load balancer on AWS you can optionally lock down access
  ## to a given IP range. Provide a list of IPs that are allowed via a
  ## security group.
  #serviceSourceRanges:
  #  - 130.155.157.0/24

  www:
    image: "entity-nginx"
    tag: "v1.3.0"
    memory: 256Mi
    cpu: 200m
    containerPort: 8851
  app:
    image: "entity-app"
    memory: 1024Mi
    tag: "v1.5.2"
    debug: "true"
    containerPort: 8000
  Replicas: 1

workers:
  imageRegistery: "quay.io/n1analytics"
  image: "entity-app"
  tag: "v1.5.2"
  replicas: 1
  debug: "true"
# Single core should do 10 M/s
  # A worker with ~3 cores should do 30 M/s
  # There is some overhead for fetching data for each task - ~15s per 100K entities
  # The trade off is that intermediate jobs won't scale much. For instance 100k x 100k
  # will only be split into 2 or 3 jobs. So for demos and testing we have a small job
  # setup - shouldn't be used for production with very large jobs:
  # Small job max 500M
  MAX_CHUNK_SIZE: "500000000"
  # Large job setup:
  # ~120 seconds per job
  # 120s x 30 M/s = 3600 M
#  MAX_CHUNK_SIZE: "3600000000"

  # A minimum of say 50M because any smaller than
  # this isn't worth splitting across nodes.
  MIN_CHUNK_SIZE: "50000000"

  MATCH_THRESHOLD: "0.95"

  celery:
    PREFETCH_MULTIPLIER: "2"
    MAX_TASKS_PER_CHILD: "4"

  ## https://kubernetes.io/docs/user-guide/compute-resources
  resources:
    requests:
      memory: 2Gi
      cpu: 1000m
    limits:
      memory: 8Gi
      cpu: 3000m

postgresql:
  # See available settings and defaults at:
  # https://github.com/kubernetes/charts/tree/master/stable/postgresql
  nameOverride: "db"
  postgresPassword: "x925SvzX6cuH"
  persistence:
    persistence.enabled: false
    persistence.storageClass: "slow"
    size: 20Gi
  imageTag: 9.5.4
  imagePullPolicy: IfNotPresent
  metrics:
    enabled: true
  resources:
    limits:
      memory: 8Gi
    requests:
      memory: 1Gi
      cpu: 100m


redis:
  # https://github.com/kubernetes/charts/tree/master/stable/redis#configuration
  redisPassword: "gOgRockEPtiN"
  persistence:
    persistence.storageClass: "slow"
  nameOverride: "redis"

minio:
  # https://github.com/kubernetes/charts/tree/master/stable/minio#configuration
  ## Can distribute the object store across multiple nodes...
  #mode: "distributed"
  serviceType: "ClusterIP"
  persistence:
    size: 100Gi
    storageClass: "slow"
  accessKey: "SNANDoWeruDenOCongsA"
  secretKey: "onimoUBRANeRNaLDeTyWrENTipHErYPrON"
  nameOverride: "minio"
